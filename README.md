# Zadanie-1-NN

При выполнении задания применялся фреймворк глубокого обучения Tensorflow 2. Использовалась последовательная модель (tf.keras.models.sequential) со слоями ResNet101V2, GlobalAveragePooling2D, Dense и оптимизатором Adam. 
Количество эпох - 10, batch size = 64.

Источники, использованные для выполнения задания:
1) выданный ноутбук Google Colab, в том числе информация по Tensorflow 2;
2) статья "Обзор Keras для TensorFlow": https://habr.com/ru/articles/482126/;
3) документация по keras 3 API - в частности, по приложениям: https://keras.io/api/applications/.

Сначала пробовал обучить с помощью сети ResNet50V2 на наборе tiny и на основном наборе по отдельности, но результаты оказались неудовлетворительными - точность от 1 до 37 процентов. Поэтому было принято решение использовать итеративное обучение: сначала - на наборе tiny; полученные веса загружались в модель для обучения на наборе small; полученные веса были использованы для обучения на наборе train; тестирование модели осуществлялось на последних полученных весах (best_last). 

Предполагаю, что модель, обученная без итеративного обучения, показывала неудовлетворительные результаты при тестировании только потому, что не загрузил её перед тестированием. Но возможности проверить это сейчас уже нет, так как ресурсы Google Colab потрачены на всех доступных аккаунтах, а старые веса не были сохранены. 

Результаты тестирования (на весах best_last):
1) metrics for 10% of test:
	 accuracy 0.9000:
	 balanced accuracy 0.9000:
2) metrics for test:
	 accuracy 0.9069:
	 balanced accuracy 0.9069:
3) metrics for test-tiny:
	 accuracy 0.8333:
	 balanced accuracy 0.8333.
